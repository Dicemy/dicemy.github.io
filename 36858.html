<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>深度学习&lt;Dive into deep learning&gt;_2预备知识 - Dicemy 的博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Dicemy"><meta name="msapplication-TileImage" content="/img/biaoti.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Dicemy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="所有笔记和教程都使用Pytorch框架来实现 本系列博客来自于： DIVE INTO DEEP LEARNING，李沐老师的课，Orz"><meta property="og:type" content="blog"><meta property="og:title" content="深度学习&lt;Dive into deep learning&gt;_2预备知识"><meta property="og:url" content="https://dicemy.com/36858"><meta property="og:site_name" content="Dicemy 的博客"><meta property="og:description" content="所有笔记和教程都使用Pytorch框架来实现 本系列博客来自于： DIVE INTO DEEP LEARNING，李沐老师的课，Orz"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://cdn.dicemy.work/202211012358855.jpg"><meta property="article:published_time" content="2022-11-01T15:28:02.000Z"><meta property="article:modified_time" content="2022-11-03T01:55:45.503Z"><meta property="article:author" content="Dicemy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="http://cdn.dicemy.work/202211012358855.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://dicemy.com/36858"},"headline":"深度学习<Dive into deep learning>_2预备知识","image":["http://cdn.dicemy.work/202211012358855.jpg"],"datePublished":"2022-11-01T15:28:02.000Z","dateModified":"2022-11-03T01:55:45.503Z","author":{"@type":"Person","name":"Dicemy"},"publisher":{"@type":"Organization","name":"Dicemy 的博客","logo":{"@type":"ImageObject","url":"https://dicemy.com/img/biaoti.png"}},"description":"所有笔记和教程都使用Pytorch框架来实现 本系列博客来自于： DIVE INTO DEEP LEARNING，李沐老师的课，Orz"}</script><link rel="canonical" href="https://dicemy.com/36858"><link rel="icon" href="/img/biaoti.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><link rel="dns-prefetch" href="http://dicemy.com/"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-3BC8TV17YR" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-3BC8TV17YR');</script><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/biaoti.png" alt="Dicemy 的博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a><a class="navbar-item" href="/picwall">照片墙</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Jupyter" href="https://www.dicemy.top/"><i class="fa fa-spinner"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="http://cdn.dicemy.work/202211012358855.jpg" alt="深度学习&lt;Dive into deep learning&gt;_2预备知识"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-11-01T15:28:02.000Z" title="2022/11/1 下午11:28:02">2022-11-01</time>发表</span><span class="level-item"><time dateTime="2022-11-03T01:55:45.503Z" title="2022/11/3 上午9:55:45">2022-11-03</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">15 分钟读完 (大约2217个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">深度学习&lt;Dive into deep learning&gt;_2预备知识</h1><div class="content"><p>所有笔记和教程都使用<strong>Pytorch</strong>框架来实现</p>
<p>本系列博客来自于：<a target="_blank" rel="noopener" href="http://zh-v2.d2l.ai/index.html"> DIVE INTO DEEP LEARNING</a>，<a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/~muli/">李沐</a>老师的课，Orz</p>
<span id="more"></span>

<h2 id="2-1数据操作"><a href="#2-1数据操作" class="headerlink" title="2.1数据操作"></a>2.1数据操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.arange(<span class="hljs-number">12</span>) <span class="hljs-comment">#生成一个行向量，arange中的参数是行向量的元素的个数</span><br>x.shape <span class="hljs-comment">#输出张量x的形状</span><br>x.numel() <span class="hljs-comment">#输出张量的元素的个数</span><br>X = x.reshape(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">#使用reshape来改变一个张量的形状</span><br>X = x.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">#在reshape中填充-1来表示让reshape自动计算该维度的值</span><br>torch.zeros((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment">#表示生成一个维度为2, 3, 4的元素值全为0的张量，一定要注意参数是一个元组，而不是三个数字</span><br>torch.ones((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)) <span class="hljs-comment">#维度为2, 3, 4的全为1的张量</span><br>torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">#创建一个形状为(3,4)的张量，每一个元素从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样</span><br>torch.tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]]) <span class="hljs-comment">#通过提供包含python数值的列表来生成一个张量</span><br></code></pre></td></tr></table></figure>

<p><strong>运算符：</strong></p>
<p>标量运算符：按照元素进行运算。</p>
<p>对于具有相同形状的张量，常见的标准算术运算符（<code>+</code>、<code>-</code>、<code>*</code>、<code>/</code>和<code>**</code>）都可以被升级为按元素运算</p>
<p>包括一些标量运算函数：<code>torch.exp()</code></p>
<p>同时可以使用<code>torch.cat</code>将两个张量连接在一起形成一个张量</p>
<p>同时可以使用<code>==</code>或者其他的比较运算符来实现张量中的标量的比较运算</p>
<p><code>X.sum()</code>可以实现张量中所有元素的求和</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">x + y, x - y, x * y, x / y, x ** y  <span class="hljs-comment"># **运算符是求幂运算</span><br>torch.exp(x)<br>torch.cat((X, Y), dim = <span class="hljs-number">0</span>)<br>torch.cat((X, Y), dim = <span class="hljs-number">1</span>)<br>X == Y<br>X.<span class="hljs-built_in">sum</span>()<br></code></pre></td></tr></table></figure>

<p><strong>广播机制：</strong></p>
<p>对于形状不相同的张量，可以使用广播机制来对这两个张量进行运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.arange(<span class="hljs-number">3</span>).reshape((<span class="hljs-number">3</span>, <span class="hljs-number">1</span>))<br>b = torch.arange(<span class="hljs-number">2</span>).reshape((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>a + b<br></code></pre></td></tr></table></figure>

<p>矩阵<code>a</code>将复制列， 矩阵<code>b</code>将复制行，然后再按元素相加。</p>
<p><strong>索引和切片：</strong></p>
<p>-1表示数组中最后一个元素，同时可以使用切片来取数或者批量的赋值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">X[-<span class="hljs-number">1</span>], X[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]<br>X[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>] = <span class="hljs-number">9</span><br>X[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>, :] = <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure>

<p><strong>节省内存：</strong></p>
<p>Python中默认的Z = X + Y生成的结果会新产生一个对象，原来的Z张量内存就被浪费掉了，为了避免这种情况发生，可以使用Z[:]来解决</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Z[:] = X + Y<br></code></pre></td></tr></table></figure>

<p><strong>对象的转换：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.tensor([<span class="hljs-number">3.5</span>])<br>a, a.item(), <span class="hljs-built_in">float</span>(a), <span class="hljs-built_in">int</span>(a)<br></code></pre></td></tr></table></figure>

<h2 id="2-2数据预处理"><a href="#2-2数据预处理" class="headerlink" title="2.2数据预处理"></a>2.2数据预处理</h2><p>数据的处理一般采用<strong>pandas</strong>来实现</p>
<p><strong>数据的读取：</strong></p>
<p>对于csv（逗号分隔值）文件数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 如果没有安装pandas，只需取消对以下行的注释来安装pandas</span><br><span class="hljs-comment"># !pip install pandas</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = pd.read_csv(data_file)<br><span class="hljs-built_in">print</span>(data)<br></code></pre></td></tr></table></figure>

<p><strong>处理缺失值：</strong></p>
<p>一般的“NAN”表示缺失值，一般处理缺失值的方法有：插值法和删除法。</p>
<p>位置索引iloc可以将数组分为若干部分。其中fillna表示填充数据中的NAN数据，<code>inputs.mean()</code>表示数据中每一列的均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">inputs, outputs = data.iloc[:, <span class="hljs-number">0</span>:<span class="hljs-number">2</span>], data.iloc[:, <span class="hljs-number">2</span>]<br>inputs = inputs.fillna(inputs.mean())<br><span class="hljs-built_in">print</span>(inputs)<br></code></pre></td></tr></table></figure>

<p>对于离散值或者类别值，pandas可以将这一列中的所有类别拆分成若干列，并通过标记0和1来表示该行记录是哪一个离散值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">inputs = pd.get_dummies(inputs, dummy_na=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(inputs)<br></code></pre></td></tr></table></figure>

<p><strong>转换为张量格式：</strong></p>
<p>通过<code>torch.tensor</code>将数值类型转换为张量类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)<br>X, y<br></code></pre></td></tr></table></figure>

<h2 id="2-3线性代数"><a href="#2-3线性代数" class="headerlink" title="2.3线性代数"></a>2.3线性代数</h2><p><strong>标量</strong>是只有一个元素的张量，</p>
<p><strong>向量</strong>是一维的张量</p>
<p>对于向量来说，向量的维度为向量的长度。（然而，张量的维度用来表示张量具有的轴数。）</p>
<p><strong>矩阵</strong>是向量从一阶推广到二阶的结果。</p>
<p>矩阵具有相同数量的行和列时，它被称为方阵</p>
<p>交换矩阵的行和列时，结果称为矩阵的转置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">A.T <span class="hljs-comment">#表示为A矩阵的转置</span><br></code></pre></td></tr></table></figure>

<p>对称矩阵是方阵的一种特殊类型，对称矩阵等于其本身的转置</p>
<p><strong>张量</strong>是矩阵的推广，张量具有任意数量的轴</p>
<p>张量的按元素一元运算不会该表张量的形状，相同形状的两个张量按元素运算的结果也是相同形状的张量</p>
<p>两个矩阵的按元素乘法称为Hadamard积（数学符号⊙）</p>
<p>将张量乘以或加上一个标量，不会改变该张量的形状，其中张量的每个元素都会与标量相加或相乘</p>
<p><strong>降维：</strong></p>
<p>对张量进行求和可以对张量实现降维。比如对张量进行整体求和，就是将张量沿所有的轴减低张量的维度，使其称为一个标量</p>
<p>我们还可以指定张量按照某一个轴进行降维</p>
<p>对于矩阵来说，行的轴是轴0，若对行进行降维后，行这一轴就会消失，同理矩阵的列是轴1。</p>
<p>若对一个矩阵沿一个维度降维，无论是行还是列，降维的结果都将是一个向量即一个行向量，若要沿列降维后得到一个列向量，需要使用<strong>非降维求和</strong> ，这样的求和还会保持原来矩阵的形状（行数），这样方便后续进行广播操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">A_sum_axis0 = A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>A_sum_axis0, A_sum_axis0.shape<br>A_sum_axis1 = A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br>A_sum_axis1, A_sum_axis1.shape<br>A.<span class="hljs-built_in">sum</span>(axis=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>])  <span class="hljs-comment"># SameasA.sum()</span><br>sum_A = A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>) <span class="hljs-comment">#得到的是一个列向量</span><br></code></pre></td></tr></table></figure>

<p><strong>均值：</strong></p>
<p>平均值常常通过总和除以元素总数来计算。</p>
<p>均值也可以沿指定轴降低张量的维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">A.mean(), A.<span class="hljs-built_in">sum</span>() / A.numel()<br>A.mean(axis=<span class="hljs-number">0</span>), A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>) / A.shape[<span class="hljs-number">0</span>] <span class="hljs-comment">#这样得到的是A每一列的均值，即把行进行降维并且求了每一列中每一行的均值</span><br></code></pre></td></tr></table></figure>

<p><strong>点积：</strong></p>
<p>点积是两个向量之间的操作。</p>
<p>点积就是两个向量相同位置的按元素乘积的和</p>
<p>对于向量点积来说，由于没有行向量和列向量的区分，我们可以直接将两个向量按元素进行乘法，然后对结果向量进行求和。</p>
<p>向量的点积可以计算值的加权和或者加权平均，或者夹角的余弦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.dot(x, y)<br>torch.<span class="hljs-built_in">sum</span>(x * y)<br></code></pre></td></tr></table></figure>

<p><strong>矩阵-向量积：</strong></p>
<p>矩阵向量积中的向量常常指的是列向量。</p>
<p>一个m*n的矩阵和一个维度为n的向量的矩阵向量积的结果是一个维度为m的列向量</p>
<p>我们可以把矩阵向量积看为一个维度为n的向量向维度为m的向量的一个转换。构造一个矩阵可以协助向量进行转换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.mv(A, x) <span class="hljs-comment">#matrix &amp; vector =&gt; mv</span><br></code></pre></td></tr></table></figure>

<p><strong>矩阵-矩阵乘法：</strong></p>
<p>矩阵矩阵乘法指的是一个m<em>k的矩阵和一个k\</em>n矩阵之间的矩阵乘法。</p>
<img src="http://cdn.dicemy.work/202211030935956.png" alt="image-20221103093536910" style="zoom: 80%;" />

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.mm(A, b) <span class="hljs-comment"># matrix &amp; matrix =&gt; mm</span><br></code></pre></td></tr></table></figure>

<p><strong>范数：</strong></p>
<p>范数为了表示一个向量的大小，这里的大小不是维度，而是分量的大小。</p>
<p>范数有一些性质：</p>
<ol>
<li>对向量进行成倍缩放，该向量的范数也会成倍的缩放</li>
<li>三角不等式，两个向量的和的范数应该小于等于两个向量范数的和</li>
<li>范数应该是非负的</li>
</ol>
<p>欧几里得距离被称为<strong>L2范数</strong>，L2范数是向量元素平方和的平方根：</p>
<p><img src="http://cdn.dicemy.work/202211030939147.png" alt="image-20221103093931114"></p>
<p>常常使用中L2范数会忽略下标2</p>
<p>在深度学习中，比较经常的使用L2范数的平方</p>
<p><strong>L1范数</strong>，指的是向量元素的绝对值之和：</p>
<p><img src="http://cdn.dicemy.work/202211030941604.png" alt="image-20221103094136575"></p>
<p>与L2范数相比，L1范数受异常值的影响较小</p>
<p>与向量相似，矩阵的<strong>Frobenius范数</strong>是矩阵元素的平法和的平方根，Frobenius范数满足向量范数的所有性质。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.norm(u) <span class="hljs-comment">#计算出的就是u向量的L2范数</span><br>torch.<span class="hljs-built_in">abs</span>(u).<span class="hljs-built_in">sum</span>() <span class="hljs-comment">#计算出来的就是u向量的L1范数</span><br>torch.norm(torch.ones((<span class="hljs-number">4</span>, <span class="hljs-number">9</span>))) <span class="hljs-comment">#计算出来4*9的1矩阵的Frobenius范数</span><br></code></pre></td></tr></table></figure>

<p><strong>范数的意义：</strong></p>
<p>在深度学习中，我们常常解决最优化问题，要最大化或最小化某一个指标，其中向量之间的距离即目标，就是范数。</p>
<h2 id="2-4微积分"><a href="#2-4微积分" class="headerlink" title="2.4微积分"></a>2.4微积分</h2></div><div class="article-licensing box"><div class="licensing-title"><p>深度学习&lt;Dive into deep learning&gt;_2预备知识</p><p><a href="https://dicemy.com/36858">https://dicemy.com/36858</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Dicemy</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-11-01</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-11-03</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechatpay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/3392"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Redis入门</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/5744"><span class="level-item">深度学习&lt;Dive into deep learning&gt;_1前言</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/valine/1.4.16/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "FE3KQNXvpvsHJmJl9idhXhp1-9Nh9j0Va",
            appKey: "CLLAhwQhbW5KCgp3CCPkAItO",
            placeholder: "输入你的评论\\n昵称为必填项目，在昵称处输入QQ号可以直接获取你的用户名和头像哦！",
            avatar: "mp",
            avatarForce: false,
            meta: ["nick","mail"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: true,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/touxiang.jpg" alt="Dicemy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Dicemy</p><p class="is-size-6 is-block">一只菜鸡</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 · 开封</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">29</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="http://dicemy.com/about/" target="_blank" rel="noopener">关于我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Dicemy"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="tencent://message/?uin=1583925267"><i class="fab fa-qq"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/16023197"><i class="fas fa-tv"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#2-1数据操作"><span class="level-left"><span class="level-item">1</span><span class="level-item">2.1数据操作</span></span></a></li><li><a class="level is-mobile" href="#2-2数据预处理"><span class="level-left"><span class="level-item">2</span><span class="level-item">2.2数据预处理</span></span></a></li><li><a class="level is-mobile" href="#2-3线性代数"><span class="level-left"><span class="level-item">3</span><span class="level-item">2.3线性代数</span></span></a></li><li><a class="level is-mobile" href="#2-4微积分"><span class="level-left"><span class="level-item">4</span><span class="level-item">2.4微积分</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/biaoti.png" alt="Dicemy 的博客" height="28"></a><p class="is-size-7"><span>&copy; 2023 Dicemy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客, <span id="busuanzi_value_site_pv">0</span>次访问</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="知识共享" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC 4.0" href="https://creativecommons.org/licenses/by-nc/4.0/deed.zh"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Dicemy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>